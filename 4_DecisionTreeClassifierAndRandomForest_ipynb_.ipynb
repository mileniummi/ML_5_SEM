{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4.DecisionTreeClassifierAndRandomForest.ipynb\"",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGClrhQA9SAk"
      },
      "source": [
        "# Деревья решений"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "veekMy8WRjBi"
      },
      "source": [
        "## Построение дерева"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYkVwAFiUHXj"
      },
      "source": [
        "Опишем жадный алгоритм построения бинарного дерева решений:\n",
        "1. Начинаем со всей обучающей выборки $X$, которую помещаем в корень $R_1$. \n",
        "2. Задаём функционал качества $Q(X, j, t)$ и критерий остановки. \n",
        "3. Запускаем построение из корня: $SplitNode(1, R_1)$\n",
        "\n",
        "Функция $SplitNode(m, R_m)$\n",
        "1. Если выполнен критерий остановки, то выход.\n",
        "2. Находим наилучший с точки зрения $Q$ предикат: $j, t$: $[x_j<t]$\n",
        "3. Помещаем предикат в вкршину и получаем с его помощью разбиение $X$ на две части: $R_{left} = \\lbrace x|x_j<t \\rbrace$ и $R_{right} = \\lbrace x|x_j \\geqslant t \\rbrace$\n",
        "4. Поместим $R_{left}$ и $R_{right}$ соответсвенно в левое и правое поддерево.\n",
        "5. Рекурсивно повторяем $SplitNode(left, R_{left})$ и $SplitNode(right, R_{right})$.\n",
        "\n",
        "В конце поставим в соответствие каждому листу ответ. Для задачи классификации - это самый частый среди объектов класс или вектор с долями классов (можно интерпретировать как вероятности):\n",
        "$$ c_v = \\arg \\max_{k\\in Y} \\sum_{(x_i,y_i) \\in R_v} [y_i=k]  $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9P6FsdBog4Ai"
      },
      "source": [
        "## Функционал качества для деревьев решений\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VAKO0aykGBD"
      },
      "source": [
        "Энтропия Шеннона для системы с N возможными состояниями определяется по формуле:\n",
        "$$H = - \\sum_{i=0}^{N} p_i\\log_2p_i $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5582B-1Fn2bw"
      },
      "source": [
        "где $p_i$ – вероятности нахождения системы в $i$-ом состоянии. \n",
        "\n",
        "Это очень важное понятие теории информации, которое позволяет оценить количество информации (степень хаоса в системе). Чем выше энтропия, тем менее упорядочена система и наоборот. С помощью энтропии мы формализуем функционал качества для разделение выборки (для задачи классификации)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbcMUd7bvk05"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import random\n",
        "from pprint import pprint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AdLxP9CowTm"
      },
      "source": [
        "Код для расчёта энтропии:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mT8Jq8Av2sM"
      },
      "source": [
        "def entropy(y):\n",
        "    \n",
        "    _, counts = np.unique(y, return_counts=True)\n",
        "\n",
        "    probabilities = counts / counts.sum()\n",
        "    entropy = sum(probabilities * -np.log2(probabilities))\n",
        "     \n",
        "    return entropy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xk9etb2vo7fK"
      },
      "source": [
        "Здесь $y$ - это массив значений целевой переменной"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07TCw0USzLus"
      },
      "source": [
        "Энтропия – по сути степень хаоса (или неопределенности) в системе. Уменьшение энтропии называют приростом информации (information gain, IG).\n",
        "\n",
        "Обочначим $R_v$ - объекты, которые нужно разделить в помощью предиката в вершине $v$. Запишем формулу для расчёта информационного прироста:\n",
        "$$ Q = IG = H(R_v) - (H(R_{left})+H(R_{right}))$$\n",
        "\n",
        "На каждом шаге нам нужно максимизировать этот функционал качества. Как это делать? Например, так можно перебрать $t$ для выбранного $j$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trEWHDoXg_p9"
      },
      "source": [
        "Предыдущая версия формулы прироста информации слишком упрощена. В работе необходимо использовать более устойчивую формулу, которая учитывает не только энтропию подмножеств, но и их размер. \n",
        "\n",
        "$$ Q = IG = H(R_v) - \\Big (\\frac{|R_{left}|} {|R_{v}|} H(R_{left})+ \\frac{|R_{right}|} {|R_{v}|} H(R_{right})\\Big)$$\n",
        "\n",
        "где, $|R_{v}|$, $|R_{left}|$ и $|R_{right}|$ - количество элементов в соответствующих множествах."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xmN6V_N1xBr"
      },
      "source": [
        "\n",
        "### Задание 4.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWFHZScF2CBF"
      },
      "source": [
        "Реализуйте алгоритм построения дерева. Должны быть отдельные функции (методы) для расчёта энтропии (уже есть), для разделения дерева (используйте `pandas`), для подсчёта функционала качества $IG$, для выбора наилучшего разделения (с учетом признакоd и порогов), для проверки критерия остановки.\n",
        "\n",
        "Для набора данных `iris` реализуйте алгоритм и минимум три из разными критерия остановки из перечисленных ниже:\n",
        "* максимальной глубины дерева = 5\n",
        "* минимального числа объектов в листе = 5\n",
        "* максимальное количество листьев в дереве = 5\n",
        "* purity (остановка, если все объекты в листе относятся к одному классу)\n",
        "\n",
        "Реализуйте функцию `predict` (на вход функции подаётся датафрейм с объектами)\n",
        "\n",
        "Оцените точность каждой модели с помощью метрики точность (`from sklearn.metrics import accuracy_score` или реализовать свою)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LymEQ4n0X1e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56620a59-4e3e-4777-d0bd-b6abcfefc640"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "class DecisionTree:\n",
        "    def __init__(self, min_samples=1, max_depth=np.inf, max_features=np.inf):\n",
        "        self.tree = None\n",
        "        self.min_samples = min_samples\n",
        "        self.max_depth = max_depth\n",
        "        self.features_number = None\n",
        "        self.node_splits_on_feature = []\n",
        "        self.feature_importances_ = None \n",
        "        self.max_features = max_features\n",
        "\n",
        "    # check the purity of data\n",
        "    @staticmethod\n",
        "    def pure(data):\n",
        "        # take the last column of data\n",
        "        label = data[:, -1]\n",
        "        unique_classes = np.unique(label)\n",
        "        return len(unique_classes) == 1\n",
        "\n",
        "    @staticmethod\n",
        "    def classify(data):\n",
        "        \"\"\":returns the class which occurs most of all\"\"\"\n",
        "        label = data[:, -1]\n",
        "        unique_classes, unique_classes_counts = np.unique(label, return_counts=True)\n",
        "        return unique_classes[unique_classes_counts.argmax()]\n",
        "\n",
        "    @staticmethod\n",
        "    def splits(data, max_features):\n",
        "        \"\"\":returns all potential splits for given data\"\"\"\n",
        "        potential_splits = {}\n",
        "        _, columns = np.shape(data)\n",
        "        columns = [column_index for column_index in range(columns - 1)]\n",
        "        if len(columns) > max_features:\n",
        "            columns = random.sample(columns, max_features)\n",
        "\n",
        "        for column_index in columns:\n",
        "            values = data[:, column_index]\n",
        "            unique_values = np.unique(values)\n",
        "            potential_splits[column_index] = unique_values\n",
        "        return potential_splits\n",
        "\n",
        "    @staticmethod\n",
        "    def split_data(data, column_to_split, value_to_split):\n",
        "        split_column = data[:, column_to_split]\n",
        "        data_left = data[split_column <= value_to_split]\n",
        "        data_right = data[split_column > value_to_split]\n",
        "        return data_left, data_right\n",
        "\n",
        "    # calculate entropy\n",
        "    @staticmethod\n",
        "    def entropy(data):\n",
        "        label = data[:, -1]\n",
        "        _, counts = np.unique(label, return_counts=True)\n",
        "        probabilities = counts / counts.sum()\n",
        "        entropy = sum(probabilities * -np.log2(probabilities))\n",
        "        return entropy\n",
        "\n",
        "    @staticmethod\n",
        "    def overall_entropy(data_left, data_right):\n",
        "        \"\"\"calculate entropy for a single split\"\"\"\n",
        "        data_points_len = len(data_left) + len(data_right)\n",
        "        left_data_percent = len(data_left) / data_points_len\n",
        "        right_data_percent = len(data_right) / data_points_len\n",
        "\n",
        "        return (left_data_percent * DecisionTree.entropy(data_left)\n",
        "                + right_data_percent * DecisionTree.entropy(data_right))\n",
        "\n",
        "    # find best split\n",
        "    @staticmethod\n",
        "    def best_split(data, splits):\n",
        "        \"\"\"finds the best way to split data depending on each split entropy\"\"\"\n",
        "        overall_entropy = np.inf\n",
        "        for column in splits:\n",
        "            for value in splits[column]:\n",
        "                data_left, data_right = DecisionTree.split_data(data, column, value)\n",
        "                curr_overall_entropy = DecisionTree.overall_entropy(data_left, data_right)\n",
        "                if curr_overall_entropy <= overall_entropy:\n",
        "                    overall_entropy = curr_overall_entropy\n",
        "                    best_split_column = column\n",
        "                    best_split_value = value\n",
        "        return best_split_column, best_split_value\n",
        "\n",
        "    def features_importance(self):\n",
        "        all_nodes = len(self.node_splits_on_feature)\n",
        "        node_counts = Counter(self.node_splits_on_feature)\n",
        "        features_importance_ = {node: node_count / all_nodes for node, node_count in node_counts.most_common()}\n",
        "        features_importance = []\n",
        "        for i in range(self.features_number):\n",
        "            if i in features_importance_.keys():\n",
        "                features_importance.append(features_importance_[i])\n",
        "            else:\n",
        "                features_importance.append(0)\n",
        "        self.feature_importances_ = features_importance\n",
        "\n",
        "    def build_tree(self, data_frame, counter=0):\n",
        "        \"\"\"recursively builds a tree\"\"\"\n",
        "        # prepare data\n",
        "        if counter == 0:\n",
        "            data = data_frame.values\n",
        "        else:\n",
        "            data = data_frame\n",
        "        # when to stop\n",
        "        if DecisionTree.pure(data) or len(data) < self.min_samples or counter >= self.max_depth:\n",
        "            return DecisionTree.classify(data)\n",
        "        else:\n",
        "            counter += 1\n",
        "            splits = DecisionTree.splits(data, self.max_features)\n",
        "            split_column, split_value = DecisionTree.best_split(data, splits)\n",
        "            data_left, data_right = DecisionTree.split_data(data, split_column, split_value)\n",
        "            self.node_splits_on_feature.append(split_column)\n",
        "\n",
        "            # check for empty nodes\n",
        "            if len(data_left) == 0 or len(data_right) == 0:\n",
        "                return DecisionTree.classify(data)\n",
        "            # create subtree\n",
        "            key = \"column {} :split_by_value {}\".format(split_column, split_value)\n",
        "            sub_tree = {key: []}\n",
        "\n",
        "            # recursion\n",
        "            sub_tree[key].append(DecisionTree.build_tree(self, data_left, counter))\n",
        "            sub_tree[key].append(DecisionTree.build_tree(self, data_right, counter))\n",
        "            return sub_tree\n",
        "\n",
        "    @staticmethod\n",
        "    def classify_data(data, tree):\n",
        "        \"\"\"goes through the tree in order to find class of given exemplar\"\"\"\n",
        "        node = list(tree.keys())[0]\n",
        "        _, feature_name, _, split_value = node.split()\n",
        "        feature_name = int(feature_name)\n",
        "        if data[feature_name] <= float(split_value):\n",
        "            sub_tree = tree[node][0]\n",
        "        else:\n",
        "            sub_tree = tree[node][1]\n",
        "        if isinstance(sub_tree, dict):\n",
        "            return DecisionTree.classify_data(data, sub_tree)\n",
        "        else:\n",
        "            return sub_tree\n",
        "\n",
        "    def fit(self, train, target):\n",
        "        data_frame = pd.DataFrame(train)\n",
        "        _, self.features_number = np.shape(data_frame)\n",
        "        data_frame['label'] = target\n",
        "        self.tree = DecisionTree.build_tree(self, data_frame)\n",
        "\n",
        "    def predict(self, data_frame):\n",
        "        if not isinstance(data_frame, pd.DataFrame):\n",
        "            data_frame = pd.DataFrame(data_frame)\n",
        "        return data_frame.apply(self.classify_data, axis=1, args=(self.tree,))\n",
        "        self.features_importance()\n",
        "    \n",
        "    def predict_proba(self, data_frame):\n",
        "      if not isinstance(data_frame, pd.DataFrame):\n",
        "            data_frame = pd.DataFrame(data_frame)\n",
        "      prediction = data_frame.apply(self.classify_data, axis=1, args=(self.tree,))\n",
        "      probability = []\n",
        "      for class_ in prediction.values:\n",
        "          class_prob = []\n",
        "          for i in range(self.features_number-1):\n",
        "            if i == class_:\n",
        "              class_prob.append(1.)\n",
        "            else:\n",
        "              class_prob.append(0.)\n",
        "          probability.append(class_prob)\n",
        "      return probability\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # preparing data\n",
        "    print(iris.data)\n",
        "    iris = load_iris()\n",
        "    train_data, test_data, train_target, test_target = train_test_split(iris.data, iris.target, train_size=0.7)\n",
        "\n",
        "    # sklearn model\n",
        "    sklearn_model = DecisionTreeClassifier()\n",
        "    sklearn_model.fit(train_data, train_target)\n",
        "    sklearn_prediction = sklearn_model.predict(test_data)\n",
        "\n",
        "    # my model\n",
        "    model = DecisionTree(min_samples=5, max_depth=5)\n",
        "    model.fit(train_data, train_target)\n",
        "    prediction = model.predict(test_data)\n",
        "\n",
        "    print(\"sklearn tree realization\", accuracy_score(sklearn_prediction, test_target))\n",
        "    print(\"My tree realization\", accuracy_score(prediction, test_target))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[5.1 3.5 1.4 0.2]\n",
            " [4.9 3.  1.4 0.2]\n",
            " [4.7 3.2 1.3 0.2]\n",
            " [4.6 3.1 1.5 0.2]\n",
            " [5.  3.6 1.4 0.2]\n",
            " [5.4 3.9 1.7 0.4]\n",
            " [4.6 3.4 1.4 0.3]\n",
            " [5.  3.4 1.5 0.2]\n",
            " [4.4 2.9 1.4 0.2]\n",
            " [4.9 3.1 1.5 0.1]\n",
            " [5.4 3.7 1.5 0.2]\n",
            " [4.8 3.4 1.6 0.2]\n",
            " [4.8 3.  1.4 0.1]\n",
            " [4.3 3.  1.1 0.1]\n",
            " [5.8 4.  1.2 0.2]\n",
            " [5.7 4.4 1.5 0.4]\n",
            " [5.4 3.9 1.3 0.4]\n",
            " [5.1 3.5 1.4 0.3]\n",
            " [5.7 3.8 1.7 0.3]\n",
            " [5.1 3.8 1.5 0.3]\n",
            " [5.4 3.4 1.7 0.2]\n",
            " [5.1 3.7 1.5 0.4]\n",
            " [4.6 3.6 1.  0.2]\n",
            " [5.1 3.3 1.7 0.5]\n",
            " [4.8 3.4 1.9 0.2]\n",
            " [5.  3.  1.6 0.2]\n",
            " [5.  3.4 1.6 0.4]\n",
            " [5.2 3.5 1.5 0.2]\n",
            " [5.2 3.4 1.4 0.2]\n",
            " [4.7 3.2 1.6 0.2]\n",
            " [4.8 3.1 1.6 0.2]\n",
            " [5.4 3.4 1.5 0.4]\n",
            " [5.2 4.1 1.5 0.1]\n",
            " [5.5 4.2 1.4 0.2]\n",
            " [4.9 3.1 1.5 0.2]\n",
            " [5.  3.2 1.2 0.2]\n",
            " [5.5 3.5 1.3 0.2]\n",
            " [4.9 3.6 1.4 0.1]\n",
            " [4.4 3.  1.3 0.2]\n",
            " [5.1 3.4 1.5 0.2]\n",
            " [5.  3.5 1.3 0.3]\n",
            " [4.5 2.3 1.3 0.3]\n",
            " [4.4 3.2 1.3 0.2]\n",
            " [5.  3.5 1.6 0.6]\n",
            " [5.1 3.8 1.9 0.4]\n",
            " [4.8 3.  1.4 0.3]\n",
            " [5.1 3.8 1.6 0.2]\n",
            " [4.6 3.2 1.4 0.2]\n",
            " [5.3 3.7 1.5 0.2]\n",
            " [5.  3.3 1.4 0.2]\n",
            " [7.  3.2 4.7 1.4]\n",
            " [6.4 3.2 4.5 1.5]\n",
            " [6.9 3.1 4.9 1.5]\n",
            " [5.5 2.3 4.  1.3]\n",
            " [6.5 2.8 4.6 1.5]\n",
            " [5.7 2.8 4.5 1.3]\n",
            " [6.3 3.3 4.7 1.6]\n",
            " [4.9 2.4 3.3 1. ]\n",
            " [6.6 2.9 4.6 1.3]\n",
            " [5.2 2.7 3.9 1.4]\n",
            " [5.  2.  3.5 1. ]\n",
            " [5.9 3.  4.2 1.5]\n",
            " [6.  2.2 4.  1. ]\n",
            " [6.1 2.9 4.7 1.4]\n",
            " [5.6 2.9 3.6 1.3]\n",
            " [6.7 3.1 4.4 1.4]\n",
            " [5.6 3.  4.5 1.5]\n",
            " [5.8 2.7 4.1 1. ]\n",
            " [6.2 2.2 4.5 1.5]\n",
            " [5.6 2.5 3.9 1.1]\n",
            " [5.9 3.2 4.8 1.8]\n",
            " [6.1 2.8 4.  1.3]\n",
            " [6.3 2.5 4.9 1.5]\n",
            " [6.1 2.8 4.7 1.2]\n",
            " [6.4 2.9 4.3 1.3]\n",
            " [6.6 3.  4.4 1.4]\n",
            " [6.8 2.8 4.8 1.4]\n",
            " [6.7 3.  5.  1.7]\n",
            " [6.  2.9 4.5 1.5]\n",
            " [5.7 2.6 3.5 1. ]\n",
            " [5.5 2.4 3.8 1.1]\n",
            " [5.5 2.4 3.7 1. ]\n",
            " [5.8 2.7 3.9 1.2]\n",
            " [6.  2.7 5.1 1.6]\n",
            " [5.4 3.  4.5 1.5]\n",
            " [6.  3.4 4.5 1.6]\n",
            " [6.7 3.1 4.7 1.5]\n",
            " [6.3 2.3 4.4 1.3]\n",
            " [5.6 3.  4.1 1.3]\n",
            " [5.5 2.5 4.  1.3]\n",
            " [5.5 2.6 4.4 1.2]\n",
            " [6.1 3.  4.6 1.4]\n",
            " [5.8 2.6 4.  1.2]\n",
            " [5.  2.3 3.3 1. ]\n",
            " [5.6 2.7 4.2 1.3]\n",
            " [5.7 3.  4.2 1.2]\n",
            " [5.7 2.9 4.2 1.3]\n",
            " [6.2 2.9 4.3 1.3]\n",
            " [5.1 2.5 3.  1.1]\n",
            " [5.7 2.8 4.1 1.3]\n",
            " [6.3 3.3 6.  2.5]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [7.1 3.  5.9 2.1]\n",
            " [6.3 2.9 5.6 1.8]\n",
            " [6.5 3.  5.8 2.2]\n",
            " [7.6 3.  6.6 2.1]\n",
            " [4.9 2.5 4.5 1.7]\n",
            " [7.3 2.9 6.3 1.8]\n",
            " [6.7 2.5 5.8 1.8]\n",
            " [7.2 3.6 6.1 2.5]\n",
            " [6.5 3.2 5.1 2. ]\n",
            " [6.4 2.7 5.3 1.9]\n",
            " [6.8 3.  5.5 2.1]\n",
            " [5.7 2.5 5.  2. ]\n",
            " [5.8 2.8 5.1 2.4]\n",
            " [6.4 3.2 5.3 2.3]\n",
            " [6.5 3.  5.5 1.8]\n",
            " [7.7 3.8 6.7 2.2]\n",
            " [7.7 2.6 6.9 2.3]\n",
            " [6.  2.2 5.  1.5]\n",
            " [6.9 3.2 5.7 2.3]\n",
            " [5.6 2.8 4.9 2. ]\n",
            " [7.7 2.8 6.7 2. ]\n",
            " [6.3 2.7 4.9 1.8]\n",
            " [6.7 3.3 5.7 2.1]\n",
            " [7.2 3.2 6.  1.8]\n",
            " [6.2 2.8 4.8 1.8]\n",
            " [6.1 3.  4.9 1.8]\n",
            " [6.4 2.8 5.6 2.1]\n",
            " [7.2 3.  5.8 1.6]\n",
            " [7.4 2.8 6.1 1.9]\n",
            " [7.9 3.8 6.4 2. ]\n",
            " [6.4 2.8 5.6 2.2]\n",
            " [6.3 2.8 5.1 1.5]\n",
            " [6.1 2.6 5.6 1.4]\n",
            " [7.7 3.  6.1 2.3]\n",
            " [6.3 3.4 5.6 2.4]\n",
            " [6.4 3.1 5.5 1.8]\n",
            " [6.  3.  4.8 1.8]\n",
            " [6.9 3.1 5.4 2.1]\n",
            " [6.7 3.1 5.6 2.4]\n",
            " [6.9 3.1 5.1 2.3]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [6.8 3.2 5.9 2.3]\n",
            " [6.7 3.3 5.7 2.5]\n",
            " [6.7 3.  5.2 2.3]\n",
            " [6.3 2.5 5.  1.9]\n",
            " [6.5 3.  5.2 2. ]\n",
            " [6.2 3.4 5.4 2.3]\n",
            " [5.9 3.  5.1 1.8]]\n",
            "sklearn tree realization 0.9333333333333333\n",
            "My tree realization 0.8888888888888888\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPAtV-NaJjwq"
      },
      "source": [
        "**Защита**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEyREnYqJhu0",
        "outputId": "f12b0318-7eb9-4218-b027-e45fc95ac35f"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "test_probabilities = sklearn_model.predict_proba(test_data)\n",
        "\n",
        "roc_auc_value = roc_auc_score(test_target, test_probabilities, multi_class='ovr')\n",
        "print(\"sklearn ROC-AUC на тестовой выборке:\", roc_auc_value) \n",
        "\n",
        "mytest_probabilities = model.predict_proba(test_data)\n",
        "my_roc_auc_value = roc_auc_score(test_target, mytest_probabilities, multi_class='ovr')\n",
        "print(\"My tree realization ROC-AUC на тестовой выборке:\", roc_auc_value) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sklearn ROC-AUC на тестовой выборке: 0.9838383838383838\n",
            "My tree realization ROC-AUC на тестовой выборке: 0.9838383838383838\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9uR1r8ZcGAU"
      },
      "source": [
        "**Построить Матрицу сопряженности**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "TQWOFf1ocPxb",
        "outputId": "ad3e33fb-a29d-469e-eeef-514facdb71b9"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "my_tree_confusion_matrix = confusion_matrix(test_target, prediction)\n",
        "my_tree_confusion_matrix = pd.DataFrame(my_tree_confusion_matrix)\n",
        "display(my_tree_confusion_matrix)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>16</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    0   1   2\n",
              "0  16   2   0\n",
              "1   0  14   1\n",
              "2   0   0  12"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkyCjLcy_CTM"
      },
      "source": [
        "##  Случайный лес"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fKZe1FyRgCa"
      },
      "source": [
        "Опишем алгоритм случайный лес (*random forest*) и попутно разберём основные идеи:\n",
        "\n",
        "1. Зададим $N$ - число деревьев в лесу.\n",
        "2. Для каждого $n$ из $N$ сгенерируем свою выборку $X_n$. Пусть $m$ - это количество объектов в $X$. При генерации каждой $X_n$ мы будем брать объекты $m$ раз с возвращением. То есть один и тот же объект может попасть в выборку несколько раз, а какие-то объекты не попадут. (Этот способ назвается бутстрап).\n",
        "3. По каждой $X_n$ построим решающее дерево $b_n$. Обычно стараются делать глубокие деревья. В качестве критериев остановки можно использовать `max_depth` или `min_samples_leaf` (например, пока в каждом листе не окажется по одному объекту). При каждом разбиении сначала выбирается $k$ (эвристика $k = \\sqrt d$, где $d$ - это число признаков объектов из выборки $X$) случайных признаков из исходных, и оптимальное разделение выборки ищется только среди них. Обратите внимание, что мы не выбрасываем оставшиеся признаки!\n",
        "4. Итоговый алгоритм будет представлять собой результат голосования (для классификации) и среднее арифметическое (для регрессии). Модификация алгоритма предполагает учёт весов каждого отдельного слабого алгоритма в ансамбле, но в этом особо нет смысла.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJBQ8lc0WyrN"
      },
      "source": [
        "### Задание 4.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y594Jn04ZTCm"
      },
      "source": [
        "В качестве набора данных используйте: https://www.kaggle.com/mathchi/churn-for-bank-customers\n",
        "\n",
        "Там есть описание и примеры работы с этими данными. Если кратко, речь идёт про задачу прогнозирования оттока клиентов. Есть данные о 10 тысячах клиентов банка, часть из которых больше не являются клиентами."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elxrNaGE0kKg"
      },
      "source": [
        "# загружаем данные\n",
        "url = \"https://raw.githubusercontent.com/mileniummi/data_for_ML/main/churn.csv?token=ANW6GMFOORSICXPOQU7QBWTBQMFGS\"\n",
        "churn = pd.read_csv(url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vk5_cBfQkaC"
      },
      "source": [
        "%%capture\n",
        "!pip install category_encoders\n",
        "from category_encoders import TargetEncoder\n",
        "\n",
        "churn_target = churn[\"Exited\"]\n",
        "churn[\"Gender\"] = TargetEncoder().fit_transform(churn[\"Gender\"], churn_target)\n",
        "churn[\"Geography\"] = TargetEncoder().fit_transform(churn[\"Geography\"], churn_target)\n",
        "churn_data = churn.drop([\"RowNumber\", \"CustomerId\", 'Surname', \"Exited\"], axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGFzq2GLGzsj"
      },
      "source": [
        "train_data, test_data, train_target, test_target = train_test_split(churn_data, churn_target, train_size=0.7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "be_mLbdVW2oG"
      },
      "source": [
        "Используя либо свою реализацию, либо  `DecisionTreeClassifier` с разными настройками из `sklearn.tree` реализйте алгоритм \"случайный лес\". \n",
        "\n",
        "Найдите наилучшие гиперпараметры этого алгоритма: количество деревьев, критерий остановки, функционал качества, минимальное количество объектов в листьях и другие.\n",
        "\n",
        "Нельзя использовать готовую реализацию случайного леса из `sklearn`.\n",
        "\n",
        "В подобных задачах очень важна интерпретируемость алгоритма. Попытайтесь оценить информативность признаков, т.е. ответить а вопрос, значения каких признаков являются самыми важными индикаторами того, что банк потеряет клиента."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anZUz1TDzh_H"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "class RandomForest:\n",
        "    def __init__(self, N=100, max_depth=100, min_samples=1):\n",
        "        self.N = N\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples = min_samples\n",
        "        self.trees = []\n",
        "    \n",
        "    def get_params(self,deep=True):\n",
        "        return {'N': self.N, 'max_depth': self.max_depth, 'min_samples': self.min_samples}\n",
        "    \n",
        "    def set_params(self, **parameters):\n",
        "        for parameter, value in parameters.items():\n",
        "            setattr(self, parameter, value)\n",
        "        return self\n",
        "    \n",
        "    def fit(self, values, target):\n",
        "        _, feature_number = np.shape(values)\n",
        "        k = int(np.sqrt(feature_number))\n",
        "        for i in range(self.N):\n",
        "            model = DecisionTreeClassifier(max_features=k, max_depth=self.max_depth, min_samples_leaf=self.min_samples)\n",
        "            state = random.randint(1, 10000)\n",
        "            values_sample = values.sample(n=len(values), random_state = state, replace=True)\n",
        "            target_sample = target.sample(n=len(values), random_state = state, replace=True)\n",
        "            model.fit(values_sample, target_sample)\n",
        "            self.trees.append(model)\n",
        "\n",
        "    def predict(self, data):\n",
        "        predictions = []\n",
        "        for model in self.trees:\n",
        "            predictions.append(model.predict(data))\n",
        "        predictions = pd.DataFrame(data=predictions)\n",
        "        return round(predictions.mean())\n",
        "\n",
        "    def features_importance(self):\n",
        "        predictions = []\n",
        "        for model in self.trees:\n",
        "            predictions.append(model.feature_importances_)\n",
        "        predictions = pd.DataFrame(data=predictions)\n",
        "        return predictions.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtNFalQhk2g3"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "params = {'N': [10, 100, 300, 600],'max_depth': [None,1, 5, 8, 15],'min_samples': [1, 2, 5, 10]}\n",
        "forest_grid = GridSearchCV(RandomForest(), params, scoring='accuracy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwlJBtw6nQy5",
        "outputId": "046a0c1f-14c7-47f4-e8c3-9a94e0c7dee4"
      },
      "source": [
        "%time\n",
        "forest_grid.fit(train_data,train_target)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
            "Wall time: 10 µs\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "GridSearchCV(cv=None, error_score=nan,\n",
              "             estimator=<__main__.RandomForest object at 0x7f2d384a9790>,\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'N': [10, 100, 300, 600],\n",
              "                         'max_depth': [None, 1, 5, 8, 15],\n",
              "                         'min_samples': [1, 2, 5, 10]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='accuracy', verbose=0)"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WqcA4BWhrXXH",
        "outputId": "d0fb116d-307a-43e0-985d-6829ac79721c"
      },
      "source": [
        "forest_grid.score(test_data, test_target) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8733333333333333"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "sM174SPzsWIu",
        "outputId": "edd24d3a-8d58-4ef6-d39a-a38bd21f6f6b"
      },
      "source": [
        "best_params = forest_grid.best_params_\n",
        "best_params"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'N': 100, 'max_depth': 15, 'min_samples': 5}"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_5tckA2e__V",
        "outputId": "176bc204-97bd-4eba-9761-28e681370ad6"
      },
      "source": [
        "model = RandomForest(100, 15, 5)\n",
        "model.fit(train_data,train_target)\n",
        "prediction = model.predict(test_data)\n",
        "print(accuracy_score(prediction, test_target))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8563333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmbsLqBDdYb-"
      },
      "source": [
        "**Построить матрицу сопряженности**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "BtLhuTBedXzb",
        "outputId": "66b59a07-3f37-4ad9-d26d-8b7993b4d715"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "my_tree_confusion_matrix = confusion_matrix(test_target, prediction)\n",
        "my_tree_confusion_matrix = pd.DataFrame(my_tree_confusion_matrix)\n",
        "display(my_tree_confusion_matrix)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2321</td>\n",
              "      <td>88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>343</td>\n",
              "      <td>248</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      0    1\n",
              "0  2321   88\n",
              "1   343  248"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ALqCdlvhfFwL",
        "outputId": "08a35e9d-a5d2-4722-bea1-a250851c4129"
      },
      "source": [
        "display(pd.DataFrame(index=churn_data.columns, data=model.features_importance().values, columns=['importance']).sort_values(by='importance', ascending=False))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>importance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Age</th>\n",
              "      <td>0.292726</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumOfProducts</th>\n",
              "      <td>0.176503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Balance</th>\n",
              "      <td>0.126886</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <td>0.107217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CreditScore</th>\n",
              "      <td>0.104322</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tenure</th>\n",
              "      <td>0.058143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>IsActiveMember</th>\n",
              "      <td>0.055662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Geography</th>\n",
              "      <td>0.046661</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Gender</th>\n",
              "      <td>0.018886</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HasCrCard</th>\n",
              "      <td>0.012993</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 importance\n",
              "Age                0.292726\n",
              "NumOfProducts      0.176503\n",
              "Balance            0.126886\n",
              "EstimatedSalary    0.107217\n",
              "CreditScore        0.104322\n",
              "Tenure             0.058143\n",
              "IsActiveMember     0.055662\n",
              "Geography          0.046661\n",
              "Gender             0.018886\n",
              "HasCrCard          0.012993"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    }
  ]
}